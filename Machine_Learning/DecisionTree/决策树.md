## 决策树
1. 熵用来度量信息是否有序
	- 熵越小越有序
	- 熵越大越无序
	- 决策树构建的时候,将无序数据进行排序,从而让信息熵变小
	- 信息增益 = 原来没有排序的信息熵(大) - 排序后有序的信息熵(小)
	- 信息增益越大,排序时候越好

2. 熵计算公式   
	![](https://i.imgur.com/OSPZh33.png)
	香农提出来的,直接使用
3. 决策树作用:    
	可以将数据属性重要性进行排序,从而进行数据清洗,清洗数据之后数据变小,机器学习训练时间缩短.清洗之后,交给其他类型算法.对于其他算法,被清洗的数据不一定不重要(算法不同)   
	数据清洗之后,数据还是交给决策树算(算法和数据对应)   
	决策树,没有返回方程,无法获取系数和截距   
	决策树可以获取概率
4. 集成学习:
	- Bagging套袋法 + 决策树 = 随机森林
	- Boosting提升法 + 决策树:
		- 梯度提升决策树
		- adaboosting提升决策树
	- 公司开发中都会采用集成算法 

5. 决策树深度,深度越小,决策树就越简单
	- 通过控制深度,将不重要的参数去掉,从而提升准确率

6. 决策树回归,调整深度max_depth,得到不同结果
	- 深度越大,认为分的份数越多
	- 回归,分成了无限多份
	- 回归和分类,没有严格的区分